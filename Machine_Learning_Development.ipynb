{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ULeseS4Jw_J4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/cleaned_dataset.csv\")"
      ],
      "metadata": {
        "id": "Px0Xybuhx6DR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8utYFx9E7AY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features and target variable\n",
        "X = df.drop(columns=['sales_price'])  # Features\n",
        "y = df['sales_price']  # Target variable\n",
        "\n",
        "# Convert categorical variables to dummy variables\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "HiCWYSyfx1iw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize models\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge Regression': Ridge(),\n",
        "    'Lasso Regression': Lasso(),\n",
        "    'Decision Tree': DecisionTreeRegressor(),\n",
        "    'Random Forest': RandomForestRegressor(),\n",
        "    'Support Vector Regression': SVR()\n",
        "}\n",
        "\n",
        "# Train models and calculate R² values\n",
        "r2_scores = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    r2_scores[model_name] = r2_score(y_test, y_pred)\n"
      ],
      "metadata": {
        "id": "IIWtRaEYyAqB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print R² values for each model\n",
        "for model_name, score in r2_scores.items():\n",
        "    print(f\"{model_name}: R² = {score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrX5YBEuyGc2",
        "outputId": "ad1cd7c0-ebe5-4b5a-c6dc-68922b1d32ee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression: R² = 0.7654\n",
            "Ridge Regression: R² = 0.7657\n",
            "Lasso Regression: R² = 0.7655\n",
            "Decision Tree: R² = 0.8555\n",
            "Random Forest: R² = 0.8953\n",
            "Support Vector Regression: R² = -0.2288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Performance Interpretation**\n",
        "\n",
        "1. **Linear Regression: R² = 0.7654**\n",
        "   - **Interpretation:** The Linear Regression model explains approximately 76.54% of the variance in the sales price. This indicates a good fit, but there might still be room for improvement with more complex models or feature engineering.\n",
        "\n",
        "2. **Ridge Regression: R² = 0.7657**\n",
        "   - **Interpretation:** Ridge Regression, which includes L2 regularization, performs similarly to Linear Regression with an R² value of 76.57%. The slight improvement suggests that regularization helps manage multicollinearity or prevents overfitting without significantly affecting performance.\n",
        "\n",
        "3. **Lasso Regression: R² = 0.7655**\n",
        "   - **Interpretation:** Lasso Regression, which includes L1 regularization, achieves an R² value of 76.55%. It’s similar to Ridge Regression and Linear Regression, with regularization helping to select a subset of important features while performing slightly worse than Ridge Regression.\n",
        "\n",
        "4. **Decision Tree: R² = 0.8555**\n",
        "   - **Interpretation:** The Decision Tree model explains 85.55% of the variance in sales price, showing a notable improvement over the linear models. This indicates that the Decision Tree can capture more complex relationships between features and target, potentially leading to better predictions.\n",
        "\n",
        "5. **Random Forest: R² = 0.8953**\n",
        "   - **Interpretation:** The Random Forest model achieves the highest R² value of 89.53%. This ensemble method of multiple decision trees offers the best performance, effectively handling complex interactions between features and reducing overfitting compared to a single decision tree.\n",
        "\n",
        "6. **Support Vector Regression: R² = -0.2288**\n",
        "   - **Interpretation:** The negative R² value for Support Vector Regression (SVR) suggests that the model performs poorly and worse than a simple mean-based model. This could indicate issues with model parameter tuning or the need for scaling the features.\n",
        "\n",
        "### **Summary**\n",
        "\n",
        "- **Best Performing Models:** Random Forest and Decision Tree, with R² values of 89.53% and 85.55%, respectively. These models handle complex feature interactions well and provide robust predictions.\n",
        "- **Regularized Linear Models:** Ridge and Lasso Regression perform similarly to standard Linear Regression, explaining about 76.5% of the variance. Regularization helps in handling multicollinearity and feature selection but does not significantly outperform linear models in this case.\n",
        "- **Poor Performance:** Support Vector Regression shows a negative R² value, indicating it is not suitable for this dataset or may require additional tuning.\n",
        "\n",
        "### **Conclusion**\n",
        "\n",
        "The Random Forest model is the most effective for predicting sales price based on the given data, with the highest R² value."
      ],
      "metadata": {
        "id": "HCi-HOvlyaEf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Optimization**"
      ],
      "metadata": {
        "id": "9FCJNmjez3SL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import r2_score\n"
      ],
      "metadata": {
        "id": "x09fhXtkytS4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n"
      ],
      "metadata": {
        "id": "wjIlzIj30AOh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Random Forest Regressor\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid,\n",
        "                           cv=5, scoring='r2', n_jobs=-1, verbose=2)\n",
        "\n",
        "# Fit GridSearchCV\n",
        "grid_search.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "spb51fQs0Crq",
        "outputId": "e6d82a1c-fd92-4d2b-f5d0-3f9fd1bd8413"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
            "540 fits failed out of a total of 1620.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "540 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1145, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 638, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.94933686 0.94996139 0.94996202\n",
            " 0.93864761 0.93916238 0.94023404 0.92383291 0.92321895 0.9244984\n",
            " 0.93656215 0.93558819 0.93514966 0.93174172 0.93048291 0.9310594\n",
            " 0.9178288  0.91804089 0.92055059 0.91196359 0.91090266 0.91233973\n",
            " 0.91196359 0.91090266 0.91233973 0.90721781 0.90684342 0.90947926\n",
            " 0.94933686 0.94996139 0.94996202 0.93864761 0.93916238 0.94023404\n",
            " 0.92383291 0.92321895 0.9244984  0.93656215 0.93558819 0.93514966\n",
            " 0.93174172 0.93048291 0.9310594  0.9178288  0.91804089 0.92055059\n",
            " 0.91196359 0.91090266 0.91233973 0.91196359 0.91090266 0.91233973\n",
            " 0.90721781 0.90684342 0.90947926        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.94531157 0.94602503 0.94637807 0.9371233  0.93773163 0.93910354\n",
            " 0.92160277 0.92203579 0.92394737 0.93506457 0.9340465  0.93436375\n",
            " 0.93167295 0.93236809 0.93200338 0.91725434 0.91631073 0.91950562\n",
            " 0.91338349 0.91197924 0.91323798 0.91338349 0.91197924 0.91323798\n",
            " 0.90622687 0.90634163 0.9087394  0.94531157 0.94602503 0.94637807\n",
            " 0.9371233  0.93773163 0.93910354 0.92160277 0.92203579 0.92394737\n",
            " 0.93506457 0.9340465  0.93436375 0.93167295 0.93236809 0.93200338\n",
            " 0.91725434 0.91631073 0.91950562 0.91338349 0.91197924 0.91323798\n",
            " 0.91338349 0.91197924 0.91323798 0.90622687 0.90634163 0.9087394\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.94933686 0.94996139 0.94996202\n",
            " 0.93864761 0.93916238 0.94023404 0.92383291 0.92321895 0.9244984\n",
            " 0.93656215 0.93558819 0.93514966 0.93174172 0.93048291 0.9310594\n",
            " 0.9178288  0.91804089 0.92055059 0.91196359 0.91090266 0.91233973\n",
            " 0.91196359 0.91090266 0.91233973 0.90721781 0.90684342 0.90947926\n",
            " 0.94933686 0.94996139 0.94996202 0.93864761 0.93916238 0.94023404\n",
            " 0.92383291 0.92321895 0.9244984  0.93656215 0.93558819 0.93514966\n",
            " 0.93174172 0.93048291 0.9310594  0.9178288  0.91804089 0.92055059\n",
            " 0.91196359 0.91090266 0.91233973 0.91196359 0.91090266 0.91233973\n",
            " 0.90721781 0.90684342 0.90947926        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.94933686 0.94996139 0.94996202 0.93864761 0.93916238 0.94023404\n",
            " 0.92383291 0.92321895 0.9244984  0.93656215 0.93558819 0.93514966\n",
            " 0.93174172 0.93048291 0.9310594  0.9178288  0.91804089 0.92055059\n",
            " 0.91196359 0.91090266 0.91233973 0.91196359 0.91090266 0.91233973\n",
            " 0.90721781 0.90684342 0.90947926 0.94933686 0.94996139 0.94996202\n",
            " 0.93864761 0.93916238 0.94023404 0.92383291 0.92321895 0.9244984\n",
            " 0.93656215 0.93558819 0.93514966 0.93174172 0.93048291 0.9310594\n",
            " 0.9178288  0.91804089 0.92055059 0.91196359 0.91090266 0.91233973\n",
            " 0.91196359 0.91090266 0.91233973 0.90721781 0.90684342 0.90947926]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42), n_jobs=-1,\n",
              "             param_grid={'max_depth': [None, 10, 20, 30],\n",
              "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
              "                         'min_samples_leaf': [1, 2, 4],\n",
              "                         'min_samples_split': [2, 5, 10],\n",
              "                         'n_estimators': [100, 200, 300]},\n",
              "             scoring='r2', verbose=2)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42), n_jobs=-1,\n",
              "             param_grid={&#x27;max_depth&#x27;: [None, 10, 20, 30],\n",
              "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
              "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
              "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
              "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
              "             scoring=&#x27;r2&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42), n_jobs=-1,\n",
              "             param_grid={&#x27;max_depth&#x27;: [None, 10, 20, 30],\n",
              "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
              "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
              "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
              "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
              "             scoring=&#x27;r2&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best parameters and model\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "\n",
        "# Predict using the optimized model\n",
        "y_pred_optimized = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the optimized model\n",
        "optimized_r2 = r2_score(y_test, y_pred_optimized)\n",
        "print(\"Optimized Random Forest R²:\", optimized_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qskfsaU0FEA",
        "outputId": "c7b82f2c-5d5a-48c3-a5da-c37b4f2a620a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
            "Optimized Random Forest R²: 0.9361852439925779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Interpretation\n",
        "\n",
        "param_grid: Specifies the hyperparameters to be tested.\n",
        "\n",
        "--> GridSearchCV: Searches through the parameter grid using cross-validation to find the best combination of hyperparameters.\n",
        "\n",
        "--> best_params_: Displays the best hyperparameters found during the search.\n",
        "\n",
        "--> best_estimator_: The model with the best parameters.\n",
        "\n",
        "--> r2_score(): Evaluates the R² value of the optimized model."
      ],
      "metadata": {
        "id": "lm_QfyCj0_Va"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Steps Taken to Improve Model Performance\n",
        "\n",
        "#### Objective:\n",
        "To improve the performance of the Random Forest model for predicting sales price.\n",
        "\n",
        "#### Steps Taken:\n",
        "\n",
        " **Hyperparameter Tuning:**\n",
        "   - **Parameter Grid Definition:** Defined a parameter grid for `GridSearchCV` including:\n",
        "     - `n_estimators`: Number of trees in the forest.\n",
        "     - `max_depth`: Maximum depth of each tree.\n",
        "     - `min_samples_split`: Minimum number of samples required to split an internal node.\n",
        "     - `min_samples_leaf`: Minimum number of samples required at a leaf node.\n",
        "     - `max_features`: Number of features to consider for the best split.\n",
        "   - **GridSearchCV Initialization:** Used `GridSearchCV` to perform an exhaustive search over the parameter grid, evaluating the model using 5-fold cross-validation.\n",
        "\n",
        " **Model Training and Evaluation:**\n",
        "   - **Training:** Trained the Random Forest model with the best hyperparameters found by `GridSearchCV`.\n",
        "   - **Prediction:** Used the optimized model to predict sales prices on the test set.\n",
        "   - **Performance Evaluation:** Evaluated the model's performance using the R² score, which measures the proportion of variance in the target variable that is predictable from the features.\n",
        "\n",
        "#### Results:\n",
        "\n",
        "- **Best Parameters:** The optimal hyperparameters for the Random Forest model are:\n",
        "  - `max_depth`: None\n",
        "  - `max_features`: 'sqrt'\n",
        "  - `min_samples_leaf`: 1\n",
        "  - `min_samples_split`: 2\n",
        "  - `n_estimators`: 300\n",
        "\n",
        "- **Optimized Random Forest R²:** The R² value of the optimized Random Forest model is `0.9362`, indicating that approximately 93.62% of the variance in the sales price is explained by the model. This reflects a significant improvement in model performance compared to the initial version.\n",
        "\n",
        "#### Conclusion:\n",
        "\n",
        "The optimization process successfully enhanced the Random Forest model's performance through hyperparameter tuning. The increased R² score demonstrates a more accurate prediction of sales prices, highlighting the effectiveness of the optimized model.\n"
      ],
      "metadata": {
        "id": "-Zl7ni8i1qQK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J80hyEKD1uGV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}